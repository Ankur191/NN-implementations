{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23127567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d6bcabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a68fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5c5c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18c838cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnist.data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f72ad383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnist.target).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d06c5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAALGUlEQVR4nO3d/6uW9R3H8ddrR81Vplu2Co8sGSXEYlnOIUYwpWErKthYCjUWA2FQFMmiRmPbPxDuhxGI1YJc0qwgWl8Wq2iBM7/kKr8Nk4ZHKo2+C6kn3/vh3ILFsXPd97muz3Wf954PkM6Xm/vzvrGn132uc9/XxxEhAHl8re0BANSLqIFkiBpIhqiBZIgaSGZSE3c6xafEVJ3WxF23anhm2cd0zjnvF1tr/6EZxdaaOnS02FpxdLjYWiV9pkM6Eoc92vcaiXqqTtMPvKSJu27Vez9ZWHS9X69cV2yt3265tthaF9z+drG1ht95t9haJW2Mf5z0ezz9BpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSqRS17aW2d9veY/vOpocC0Lsxo7Y9IOlPkq6UdKGk5bYvbHowAL2pcqReIGlPROyNiCOS1kkq90JhAF2pEvUsSftO+Hyo87UvsL3C9mbbm4/qcF3zAehSbSfKImJ1RMyPiPmTdUpddwugS1Wi3i9p9gmfD3a+BqAPVYl6k6Tzbc+xPUXSMklPNDsWgF6NeZGEiBi2fbOkZyUNSLo/IrY3PhmAnlS68klEPCXpqYZnAVADXlEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJNPIDh1ZldwxQ5KWTfug2FqrZnxabK2/bX222FqX/v5XxdaSpJmrNxRdbzQcqYFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSKbKDh332z5g+40SAwEYnypH6j9LWtrwHABqMmbUEfGSpPcLzAKgBrW9S8v2CkkrJGmqTq3rbgF0iW13gGQ4+w0kQ9RAMlV+pfWwpA2S5toesv3L5scC0Ksqe2ktLzEIgHrw9BtIhqiBZIgaSIaogWSIGkiGqIFkiBpIZsJvuzO8+NJiay2btq3YWpJ05dJlxdaa/tquYmv97OUlxdZ6f97nxdaSpJlFVxsdR2ogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpKpco2y2bZfsL3D9nbbt5YYDEBvqrz2e1jSyojYanuapC22n4uIHQ3PBqAHVbbdeTsitnY+/kTSTkmzmh4MQG+6epeW7fMkzZO0cZTvse0O0AcqnyizfbqkRyXdFhEff/n7bLsD9IdKUduerJGg10bEY82OBGA8qpz9tqT7JO2MiHuaHwnAeFQ5Ui+SdKOkxba3df78uOG5APSoyrY7L0tygVkA1IBXlAHJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQzITfS+uzM8s9hLsPXFRsLUk6VnB/q5I2vf6dtkdIjSM1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMlQsPTrX9iu1/d7bd+UOJwQD0psprLA9LWhwRn3YuFfyy7acj4l8NzwagB1UuPBiSPu18OrnzJ5ocCkDvql7Mf8D2NkkHJD0XEaNuu2N7s+3NR3W45jEBVFUp6oj4PCIuljQoaYHt745yG7bdAfpAV2e/I+JDSS9IWtrINADGrcrZ77Nsz+h8/HVJV0jK+UZfIIEqZ7/PlfSg7QGN/CPwSEQ82exYAHpV5ez3axrZkxrABMAryoBkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIZuJvu/ONcv8urd2wsNhaknSBXim6XimTph8pttbwR1OKrdUvOFIDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBM5ag7F/R/1TYXHQT6WDdH6lsl7WxqEAD1qLrtzqCkqyStaXYcAONV9Ui9StIdko6d7AbspQX0hyo7dFwt6UBEbPmq27GXFtAfqhypF0m6xvZbktZJWmz7oUanAtCzMaOOiLsiYjAizpO0TNLzEXFD45MB6Am/pwaS6epyRhHxoqQXG5kEQC04UgPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJTPhtd6Z+cNL3mNTu+xe9WWwtSfqo4FqTzjm72FrXX/iVbyOo1SNPX1ZsrX7BkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWQqvUy0cyXRTyR9Lmk4IuY3ORSA3nXz2u8fRsR7jU0CoBY8/QaSqRp1SPq77S22V4x2A7bdAfpD1affl0XEftvfkvSc7V0R8dKJN4iI1ZJWS9IZ/mbUPCeAiiodqSNif+e/ByQ9LmlBk0MB6F2VDfJOsz3t+MeSfiTpjaYHA9CbKk+/z5b0uO3jt/9LRDzT6FQAejZm1BGxV9L3CswCoAb8SgtIhqiBZIgaSIaogWSIGkiGqIFkiBpIZsJvu3PG7nKb0/xu8Mlia0nSz1fcXmytydcdLLZWSXPu2tD2CMVxpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJlKUdueYXu97V22d9pe2PRgAHpT9bXff5T0TET81PYUSac2OBOAcRgzatvTJV0u6ReSFBFHJB1pdiwAvary9HuOpIOSHrD9qu01net/fwHb7gD9oUrUkyRdIuneiJgn6ZCkO798o4hYHRHzI2L+ZJ1S85gAqqoS9ZCkoYjY2Pl8vUYiB9CHxow6It6RtM/23M6Xlkja0ehUAHpW9ez3LZLWds5875V0U3MjARiPSlFHxDZJ85sdBUAdeEUZkAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8lM+L20jr22q9ha19+7sthaknT3yoeLrbXqzSXF1tp08UCxtf4fcaQGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIZM2rbc21vO+HPx7ZvKzAbgB6M+TLRiNgt6WJJsj0gab+kx5sdC0Cvun36vUTSmxHx3yaGATB+3b6hY5mkUd9lYHuFpBWSNJX984DWVD5Sd675fY2kv472fbbdAfpDN0+/r5S0NSLebWoYAOPXTdTLdZKn3gD6R6WoO1vXXiHpsWbHATBeVbfdOSTpzIZnAVADXlEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKOiPrv1D4oqdu3Z86U9F7tw/SHrI+Nx9Web0fEWaN9o5Goe2F7c0TMb3uOJmR9bDyu/sTTbyAZogaS6aeoV7c9QIOyPjYeVx/qm5+pAdSjn47UAGpA1EAyfRG17aW2d9veY/vOtuepg+3Ztl+wvcP2dtu3tj1TnWwP2H7V9pNtz1In2zNsr7e9y/ZO2wvbnqlbrf9M3dkg4D8auVzSkKRNkpZHxI5WBxsn2+dKOjcittqeJmmLpOsm+uM6zvbtkuZLOiMirm57nrrYflDSPyNiTecKuqdGxIctj9WVfjhSL5C0JyL2RsQRSeskXdvyTOMWEW9HxNbOx59I2ilpVrtT1cP2oKSrJK1pe5Y62Z4u6XJJ90lSRByZaEFL/RH1LEn7Tvh8SEn+5z/O9nmS5kna2PIodVkl6Q5Jx1qeo25zJB2U9EDnR4s1nYtuTij9EHVqtk+X9Kik2yLi47bnGS/bV0s6EBFb2p6lAZMkXSLp3oiYJ+mQpAl3jqcfot4vafYJnw92vjbh2Z6skaDXRkSWyysvknSN7bc08qPSYtsPtTtSbYYkDUXE8WdU6zUS+YTSD1FvknS+7TmdExPLJD3R8kzjZtsa+dlsZ0Tc0/Y8dYmIuyJiMCLO08jf1fMRcUPLY9UiIt6RtM/23M6XlkiacCc2u90gr3YRMWz7ZknPShqQdH9EbG95rDosknSjpNdtb+t87TcR8VR7I6GCWySt7Rxg9kq6qeV5utb6r7QA1Ksfnn4DqBFRA8kQNZAMUQPJEDWQDFEDyRA1kMz/ACA9oV03rwJJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0658f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(mnist.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "487bdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=pd.DataFrame(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80a59323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fda8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize ann\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=32,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "ann.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "05b4f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "66/66 [==============================] - 1s 2ms/step - loss: -51.7559 - accuracy: 0.1106\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -52.7668 - accuracy: 0.1461\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -52.9676 - accuracy: 0.1684\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -53.3200 - accuracy: 0.1949\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -53.3925 - accuracy: 0.1949\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -53.3870 - accuracy: 0.1997\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.4205 - accuracy: 0.1997\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: -53.4556 - accuracy: 0.2032\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5007 - accuracy: 0.2025\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5860 - accuracy: 0.2032\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5984 - accuracy: 0.2060\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5997 - accuracy: 0.2067\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5999 - accuracy: 0.2067\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.6001 - accuracy: 0.2067\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.4350 - accuracy: 0.1907\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.4378 - accuracy: 0.1942\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -52.1978 - accuracy: 0.1106\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.1626 - accuracy: 0.1844\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -52.4797 - accuracy: 0.1364\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.0538 - accuracy: 0.1635\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.3387 - accuracy: 0.2032\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.4580 - accuracy: 0.2025\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5403 - accuracy: 0.1997\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5673 - accuracy: 0.2018\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5874 - accuracy: 0.2046\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5895 - accuracy: 0.2060\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5896 - accuracy: 0.2060\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5897 - accuracy: 0.2060\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5897 - accuracy: 0.2060\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5898 - accuracy: 0.2060\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5898 - accuracy: 0.2060\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: -53.5899 - accuracy: 0.2060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2333985ba00>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train, y_train, batch_size = 22, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd0f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
